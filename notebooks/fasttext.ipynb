{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a5ba623-d93d-41b7-bea3-b2303b09510c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"HF_HOME\"] = \"/projects/bhuang/.cache/huggingface\"\n",
    "# os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f079ccd-8814-4089-9244-e63df1decc15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhuang/anaconda3/envs/ocd-10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import math\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import fasttext\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ffbc79-5917-40f9-a248-7e340665229a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d5d1c9d-b73a-45c0-b762-b19771e0e6c9",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186bf501-cd02-461c-8a76-bbe1b6198025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drbenchmark_quaero\n",
    "\n",
    "data_files = {\n",
    "    \"train\": [\n",
    "        # \"/home/bhuang/icd_10/data/quaero_icd10_by_category_resplitted/drbenchmark_quaero-medline-train-cls-mistral_large_instruct_2407-processed.jsonl\",\n",
    "        # \"/home/bhuang/icd_10/data/quaero_icd10_by_category_resplitted/drbenchmark_quaero-emea-train-cls-mistral_large_instruct_2407-processed.jsonl\",\n",
    "        \"/home/bhuang/icd_10/data/quaero_icd10_by_category_resplitted/drbenchmark_quaero-emea_medline-train-upsampled65.jsonl\",\n",
    "    ],\n",
    "    \"valid\": [\n",
    "        \"/home/bhuang/icd_10/data/quaero_icd10_by_category_resplitted/drbenchmark_quaero-medline-validation-cls-mistral_large_instruct_2407-processed.jsonl\",\n",
    "        \"/home/bhuang/icd_10/data/quaero_icd10_by_category_resplitted/drbenchmark_quaero-emea-validation-cls-mistral_large_instruct_2407-processed.jsonl\",\n",
    "    ],\n",
    "    # \"test\": [\n",
    "    #     \"/home/bhuang/icd_10/data/quaero_icd10_by_category_resplitted/drbenchmark_quaero-medline-test-cls-mistral_large_instruct_2407-processed.jsonl\",\n",
    "    #     \"/home/bhuang/icd_10/data/quaero_icd10_by_category_resplitted/drbenchmark_quaero-emea-test-cls-mistral_large_instruct_2407-processed.jsonl\",\n",
    "    # ],\n",
    "    \"test_quaero_medline\": [\n",
    "        \"/home/bhuang/icd_10/data/quaero_icd10_by_category_resplitted/drbenchmark_quaero-medline-test-cls-mistral_large_instruct_2407-processed.jsonl\",\n",
    "    ],\n",
    "    \"test_quaero_emea\": [\n",
    "        \"/home/bhuang/icd_10/data/quaero_icd10_by_category_resplitted/drbenchmark_quaero-emea-test-cls-mistral_large_instruct_2407-processed.jsonl\",\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47a7b55-6fd7-4888-9204-734a69fd931a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a67e7a8-41cc-4b07-9395-e875039402a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic\n",
    "\n",
    "data_files = {\n",
    "    \"train\": [\n",
    "        \"/home/bhuang/icd_10/data/synthetic/synthetic-mistral_large_instruct_2407-240909-processed-train-10k.jsonl\",\n",
    "    ],\n",
    "    \"valid\": [\n",
    "        \"/home/bhuang/icd_10/data/synthetic/synthetic-mistral_large_instruct_2407-240909-processed-validation.jsonl\",\n",
    "        \"/home/bhuang/icd_10/data/synthetic_test/synthetic-head-processed-validation.jsonl\",\n",
    "        \"/home/bhuang/icd_10/data/synthetic_test/synthetic-medium-processed-validation.jsonl\",\n",
    "        \"/home/bhuang/icd_10/data/synthetic_test/synthetic-tail-processed-validation.jsonl\",\n",
    "    ],\n",
    "    \"test_synthetic\": [\n",
    "        \"/home/bhuang/icd_10/data/synthetic/synthetic-mistral_large_instruct_2407-240909-processed-test.jsonl\",\n",
    "    ],\n",
    "    \"test_synthetic_head\": [\n",
    "        \"/home/bhuang/icd_10/data/synthetic_test/synthetic-head-processed-test.jsonl\",\n",
    "    ],\n",
    "    \"test_synthetic_medium\": [\n",
    "        \"/home/bhuang/icd_10/data/synthetic_test/synthetic-medium-processed-test.jsonl\",\n",
    "    ],\n",
    "    \"test_synthetic_tail\": [\n",
    "        \"/home/bhuang/icd_10/data/synthetic_test/synthetic-tail-processed-test.jsonl\",\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868b6dfa-3fa4-4435-a375-3790703b1960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "569d8751-28d8-485b-a474-b8758019bf12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'text', 'has_diso'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['labels', 'text', 'has_diso'],\n",
       "        num_rows: 4000\n",
       "    })\n",
       "    test_synthetic: Dataset({\n",
       "        features: ['labels', 'text', 'has_diso'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test_synthetic_head: Dataset({\n",
       "        features: ['labels', 'text', 'has_diso'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test_synthetic_medium: Dataset({\n",
       "        features: ['labels', 'text', 'has_diso'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test_synthetic_tail: Dataset({\n",
       "        features: ['labels', 'text', 'has_diso'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"json\", data_files=data_files)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54e8e3b-2631-413a-9760-9cab6bb7de84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d86b3cbb-9608-4c72-9a86-5046f2b0dab9",
   "metadata": {},
   "source": [
    "## Transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8659cd4d-6ad1-4e55-b630-de616f346be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U nltk\n",
    "# import nltk\n",
    "# nltk.download(\"stopwords\")\n",
    "# nltk.download(\"punkt\")\n",
    "# nltk.download(\"punkt_tab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67904b20-db6b-407d-a60c-72a4db498831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "# stopwords_list = stopwords.words(\"english\") + stopwords.words(\"french\")\n",
    "stopwords = set(stopwords.words(\"french\"))\n",
    "\n",
    "# default word analyzer used in TfidfVectorizer\n",
    "word_token_pattern = re.compile(r\"(?u)\\b\\w\\w+\\b\")\n",
    "\n",
    "# init SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"french\")\n",
    "\n",
    "\n",
    "# adapted to optionally keep selected symbols\n",
    "def remove_symbols(s: str, keep: str = \"\"):\n",
    "    \"\"\"\n",
    "    Replace any other markers, symbols, punctuations with a space, keeping diacritics\n",
    "    \"\"\"\n",
    "    # fmt: off\n",
    "    return \"\".join(\n",
    "        c\n",
    "        if c in keep\n",
    "        else \" \"\n",
    "        if unicodedata.category(c)[0] in \"MSP\"\n",
    "        else c\n",
    "        for c in unicodedata.normalize(\"NFKC\", s)\n",
    "    )\n",
    "    # fmt: on\n",
    "\n",
    "\n",
    "def normalize_text(s):\n",
    "    s = s.lower()  # lowercase\n",
    "\n",
    "    # normalize punkt\n",
    "    \"\"\"\n",
    "    s = unicodedata.normalize(\"NFKD\", s)  # normalize unicode chars\n",
    "    s = re.sub(r\"[´′’ʼ‘ʻ`]\", \"'\", s)  # standardize quotes and apostrophes\n",
    "    s = re.sub(r\"[−‐–—]\", \"-\", s)  # standardize hyphens and dashes\n",
    "    s = re.sub(r\"\\s*'\\s*\", \"' \", s)  # add space after apostrophe\n",
    "    s = re.sub(r\"\\s*([,.:;!?])\", r\" \\1\", s)  # add space before comma/period\n",
    "    s = re.sub(r\"\\s*([-/])\\s*\", r\" \\1 \", s)  # add spaces around slash/dash\n",
    "    s = re.sub(r\"\\(\\s*\", \"( \", s)  # add space after parentheses\n",
    "    s = re.sub(r\"\\s*\\)\", \" )\", s)  # add space before parentheses\n",
    "    \"\"\"\n",
    "\n",
    "    # remove punkt except \"'\"\n",
    "    s = remove_symbols(s, keep=\"'\")\n",
    "    s = re.sub(r\"\\s*'\\s*\", \"' \", s)  # add space after apostrophe\n",
    "\n",
    "    s = re.sub(r\"æ\", \"ae\", s)  # standarize french chars\n",
    "    s = re.sub(r\"œ\", \"oe\", s)  # standarize french chars\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()  # remove extra whitespace\n",
    "    return s\n",
    "\n",
    "\n",
    "def word_tokenize(s):\n",
    "    # return nltk.word_tokenize(s)\n",
    "    # more efficient\n",
    "    return word_token_pattern.findall(s)\n",
    "\n",
    "\n",
    "def stem_word(word):\n",
    "    return stemmer.stem(word)\n",
    "\n",
    "\n",
    "def preprocess_and_tokenize(s):\n",
    "    # normalize the text\n",
    "    s = normalize_text(s)\n",
    "    # tokenize\n",
    "    # return word_tokenize(s)\n",
    "    # tokenize, remove stopwords\n",
    "    # return [w for w in word_tokenize(s) if w not in stopwords]\n",
    "    # tokenize, remove stopwords, and stem\n",
    "    return \" \".join(stem_word(w) for w in word_tokenize(s) if w not in stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a624baa5-bcf0-4b57-91b0-8ac4a97bae7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dba59eb5-e24b-4930-855c-cf49c1175375",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=64): 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 14903.39 examples/s]\n",
      "Map (num_proc=64): 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 4000/4000 [00:00<00:00, 8083.25 examples/s]\n",
      "Map (num_proc=64): 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 2727.76 examples/s]\n",
      "Map (num_proc=64): 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 2396.21 examples/s]\n",
      "Map (num_proc=64): 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 2432.23 examples/s]\n",
      "Map (num_proc=64): 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 3130.92 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['fasttext_line'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['fasttext_line'],\n",
       "        num_rows: 4000\n",
       "    })\n",
       "    test_synthetic: Dataset({\n",
       "        features: ['fasttext_line'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test_synthetic_head: Dataset({\n",
       "        features: ['fasttext_line'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test_synthetic_medium: Dataset({\n",
       "        features: ['fasttext_line'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test_synthetic_tail: Dataset({\n",
       "        features: ['fasttext_line'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fmt: off\n",
    "dataset = dataset.map(\n",
    "    # lambda x: {\"fasttext_line\": \" \".join(\"__label__\" + l for l in x[\"labels\"]) + \" \" + x[\"text\"]},\n",
    "    lambda x: {\"fasttext_line\": \" \".join(\"__label__\" + l for l in x[\"labels\"]) + \" \" + preprocess_and_tokenize(x[\"text\"])},\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    "    num_proc=64,\n",
    ")\n",
    "# fmt: on\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09e0a83-4bda-4c4f-ac95-8a8f19c557b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4a14f39-3bd6-4605-b7a2-e7c5cbcc09cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to fasttext format\n",
    "\n",
    "# data_dir = \"tmp_data/quaero\"\n",
    "# data_dir = \"tmp_data/quaero_upsampled65\"\n",
    "data_dir = \"tmp_data/synthetic_v1\"\n",
    "\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "for name, ds in dataset.items():\n",
    "    output_file = f\"{data_dir}/{name}.txt\"\n",
    "    # ds.to_json(output_file, orient=\"records\", lines=True, force_ascii=False)\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        for sample in ds:\n",
    "            f.write(sample[\"fasttext_line\"] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d0a0a0-bfde-4c5e-a7ab-e913b983308a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76ae9656-dfe9-4621-8287-3cd2269151a9",
   "metadata": {},
   "source": [
    "## Custom tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec831f6-85fd-4c7b-88f3-4f1e6ae3d940",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"tmp_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202809ec-b1b1-4200-b0d1-6295fcdae195",
   "metadata": {},
   "outputs": [],
   "source": [
    "FASTTEXT_LABEL = \"__label__\"\n",
    "\n",
    "\n",
    "def create_text_file(input_path: str, output_path: str, encoding: str = \"utf-8\"):\n",
    "    with open(input_path, encoding=encoding) as f_in, open(\n",
    "        output_path, \"w\", encoding=encoding\n",
    "    ) as f_out:\n",
    "\n",
    "        for line in f_in:\n",
    "            try:\n",
    "                tokens = []\n",
    "                for token in line.split(\" \"):\n",
    "                    if FASTTEXT_LABEL not in token:\n",
    "                        tokens.append(token)\n",
    "\n",
    "                text = \" \".join(tokens)\n",
    "            except ValueError as e:\n",
    "                continue\n",
    "\n",
    "            f_out.write(text)\n",
    "\n",
    "\n",
    "# get pure text\n",
    "create_text_file(f\"{data_dir}/train.txt\", f\"{data_dir}/train_text.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1c7a57-d6f4-447c-9c40-ba9cf95e5a22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdb530a-dc1a-4900-9f05-56b33d3aa247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train spm\n",
    "\n",
    "import sentencepiece as spm\n",
    "\n",
    "input_file = f\"{data_dir}/train_text.txt\"\n",
    "model_name = f\"{data_dir}/vocab/spm_unigram\"\n",
    "\n",
    "os.makedirs(os.path.dirname(model_name), exist_ok=True)\n",
    "\n",
    "\"\"\"\n",
    "!spm_train \\\n",
    "    --input={input_file} \\\n",
    "    --model_prefix={model_name} \\\n",
    "    --vocab_size=8000 \\\n",
    "    --character_coverage=0.9995 \\\n",
    "    --model_type=unigram\n",
    "\"\"\"\n",
    "\n",
    "spm.SentencePieceTrainer.train(\n",
    "    input=input_file,\n",
    "    model_prefix=model_name,\n",
    "    vocab_size=2000,\n",
    "    character_coverage=0.9995,\n",
    "    model_type=\"unigram\",\n",
    "    # model_type=\"bpe\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d521e3-03f7-4d38-8b87-05220cab3680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16301dc-154f-46b4-b6c5-9af5656b75db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trained spm\n",
    "\n",
    "model_file = f\"{model_name}.model\"\n",
    "sp = spm.SentencePieceProcessor(model_file=model_file)\n",
    "\n",
    "\n",
    "def tokenize_text(s):\n",
    "    return \" \".join(sp.encode(s, out_type=str))\n",
    "\n",
    "\n",
    "# test\n",
    "# s = \"premi cas mondial autoréimplant membr associ trait immunosuppresseur fk 506 tacrolimus rapport préliminair 18 mois\"\n",
    "# sp.encode(s, out_type=str)\n",
    "# tokenize_text(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77a5a7c-38c0-4d2d-87c3-f5492b8ccc64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd7a89c-aae3-42c9-83a3-82d2aa10b4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokenized_file(input_path: str, output_path: str, encoding: str = \"utf-8\"):\n",
    "    with open(input_path, encoding=encoding) as f_in, open(\n",
    "        output_path, \"w\", encoding=encoding\n",
    "    ) as f_out:\n",
    "\n",
    "        for line in f_in:\n",
    "            try:\n",
    "                # the labels remains untouched during the preprocessing step as its\n",
    "                # already in a format that fasttext can consume\n",
    "                tokens = []\n",
    "                labels = []\n",
    "                for token in line.split(\" \"):\n",
    "                    if FASTTEXT_LABEL in token:\n",
    "                        labels.append(token)\n",
    "                    else:\n",
    "                        tokens.append(token)\n",
    "\n",
    "                text = \" \".join(tokens)\n",
    "                label = \" \".join(labels)\n",
    "            except ValueError as e:\n",
    "                continue\n",
    "\n",
    "            tokenized_text = tokenize_text(text)\n",
    "            new_line = label + \" \" + tokenized_text\n",
    "            f_out.write(new_line)\n",
    "            f_out.write(\"\\n\")\n",
    "\n",
    "\n",
    "# create new data files with custom tokenization\n",
    "# create_tokenized_file(f\"{data_dir}/train.txt\", f\"{data_dir}/train_tokenized.txt\")\n",
    "# create_tokenized_file(f\"{data_dir}/valid.txt\", f\"{data_dir}/valid_tokenized.txt\")\n",
    "# create_tokenized_file(f\"{data_dir}/test.txt\", f\"{data_dir}/test_tokenized.txt\")\n",
    "# create_tokenized_file(f\"{data_dir}/train_synth.txt\", f\"{data_dir}/train_synth_tokenized.txt\")\n",
    "\n",
    "for p in Path(data_dir).glob(\"*.txt\"):\n",
    "    if \"train_text\" in p.as_posix():\n",
    "        continue\n",
    "    create_tokenized_file(p.as_posix(), f'{p.with_suffix(\"\")}_tokenized.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbd092b-1088-4ef8-9d45-ec3cd714adcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f729c4c-5312-4166-a95f-a193dbc50523",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b03859d6-ebd0-4016-a134-27cae7371dbe",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0901e254-75ba-428b-bfbe-8d9d86f74f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "\n",
    "def binarize_label(y_true, y_pred):\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    mlb.fit(y_true + y_pred)\n",
    "    y_true_encoded = mlb.transform(y_true)\n",
    "    y_pred_encoded = mlb.transform(y_pred)\n",
    "    return y_true_encoded, y_pred_encoded\n",
    "\n",
    "\n",
    "# fmt: off\n",
    "def evaluate(y, preds, average=\"micro\", verbose=True):\n",
    "    \"\"\"evaluate on all metrics\"\"\"\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y, preds, average=average, zero_division=1)\n",
    "    auc_score = roc_auc_score(y, preds, average=average)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"precision: {precision:.4f}, recall: {recall:.4f}, f1: {f1:.4f}, auc_score: {auc_score:.4f}\")\n",
    "\n",
    "    return {\"precision\": precision, \"recall\": recall, \"f1\": f1, \"auc_score\": auc_score}\n",
    "# fmt: on\n",
    "\n",
    "\n",
    "def predict_evaluate(model, test_file, k=1, threshold=0.0, verbose=True):\n",
    "\n",
    "    def parse_fasttext_line(line):\n",
    "        labels, tokens = [], []\n",
    "        for token in line.strip().split(\" \"):\n",
    "            if model.label not in token:\n",
    "                tokens.append(token)\n",
    "            else:\n",
    "                labels.append(token)\n",
    "        text = \" \".join(tokens)\n",
    "        return text, labels\n",
    "\n",
    "    y_true, y_pred = [], []\n",
    "    with open(test_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            text, labels = parse_fasttext_line(line)\n",
    "            prediction, _ = model.predict(text, k=k, threshold=threshold)\n",
    "            y_pred.append(prediction)\n",
    "            y_true.append(labels)\n",
    "\n",
    "    y_true_encoded, y_pred_encoded = binarize_label(y_true, y_pred)\n",
    "\n",
    "    return evaluate(y_true_encoded, y_pred_encoded, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd8fb8e7-06e4-41ed-a00c-a3f9e561c80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how this handle labels in test but not in train set?\n",
    "\"\"\"\n",
    "def predict_evaluate(model, test_file, k=1, threshold=0.0, verbose=True):\n",
    "    _, precision, recall = model.test(valid_file, k=k, threshold=threshold)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    if verbose:\n",
    "        print(f\"precision: {precision:.4f}, recall: {recall:.4f}, f1: {f1:.4f}\")\n",
    "    return {\"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def train_predict_evaluate(\n",
    "    train_file, test_file, params=None, k=1, threshold=0.0, verbose=True\n",
    "):\n",
    "    train_params = params or {}\n",
    "    m = fasttext.train_supervised(\n",
    "        train_file,\n",
    "        # lr=params['lr'],\n",
    "        # epoch=params['epoch'],\n",
    "        # wordNgrams=params['wordNgrams'],\n",
    "        # dim=params['dim'],\n",
    "        # minCount=params['minCount'],\n",
    "        **train_params,\n",
    "    )\n",
    "\n",
    "    return m, predict_evaluate(m, test_file, k=k, threshold=threshold, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8916b5-ce90-40b6-89c6-95f12f71b779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90164728-00b9-4ebd-b273-68663c71ece6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = \"tmp_data/quaero_upsampled65\"\n",
    "\n",
    "# fmt: off\n",
    "train_file, valid_file, test_file = f\"{data_dir}/train.txt\", f\"{data_dir}/valid.txt\", f\"{data_dir}/test.txt\"\n",
    "# train_file, valid_file, test_file = f\"{data_dir}/train_tokenized.txt\", f\"{data_dir}/valid_tokenized.txt\", f\"{data_dir}/test_tokenized.txt\"\n",
    "# fmt: on\n",
    "\n",
    "test_files = [p.as_posix() for p in Path(data_dir).glob(\"test_*.txt\")]\n",
    "\n",
    "train_synth_file = f\"{data_dir}/train_synth.txt\"\n",
    "# train_synth_file = f\"{data_dir}/train_synth_tokenized.txt\"\n",
    "\n",
    "tmp_train_file = f\"{data_dir}/tmp_train.txt\"\n",
    "# tmp_train_file = f\"{data_dir}/tmp_train_tokenized.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd6bdae-0e3d-4032-a8c5-9384a17cf611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf09042d-d783-4111-8e14-c18bd56f83b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train fasttext classifier\n",
    "\n",
    "model = fasttext.train_supervised(\n",
    "    train_file,\n",
    "    lr=1,\n",
    "    epoch=500,\n",
    "    wordNgrams=5,\n",
    "    minn=3,\n",
    "    maxn=6,\n",
    "    bucket=200_000,\n",
    "    # bucket=10_000,\n",
    "    dim=1_000,\n",
    "    loss=\"ova\",\n",
    ")\n",
    "\n",
    "predict_evaluate(model, valid_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1c9f39-486c-489c-87a1-ce36c2dddada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45934f5f-ea97-4f3f-9616-ab066e74d7b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FASTTEXT_LABEL = \"__label__\"\n",
    "\n",
    "\n",
    "def read_labels(input_path: str, encoding: str = \"utf-8\"):\n",
    "    all_labels = []\n",
    "    with open(input_path, encoding=encoding) as f_in:\n",
    "        for line in f_in:\n",
    "            all_labels.append(\n",
    "                [token for token in line.split(\" \") if FASTTEXT_LABEL in token]\n",
    "            )\n",
    "    return all_labels\n",
    "\n",
    "\n",
    "all_valid_labels = read_labels(valid_file)\n",
    "avg_num_of_labels_per_sample_valid = int(np.mean([len(l) for l in all_valid_labels]))\n",
    "avg_num_of_labels_per_sample_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86a97d94-5f87-4dbf-8754-d9e5ed066aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : loss is manually set to a specific value. It will not be automatically optimized.\n",
      "Progress: 100.0% Trials:   29 Best score:  0.349433 ETA:   0h 0m 0s\n",
      "Training again with best arguments\n",
      "Read 1M words\n",
      "Number of words:  8710\n",
      "Number of labels: 933\n",
      "Progress: 100.0% words/sec/thread:  274824 lr:  0.000000 avg.loss:  5.071896 ETA:   0h 0m 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f': <fasttext_pybind.fasttext object at 0x7f2afba729b0>, '_words': None, '_labels': None, 'lr': 0.4165878098673522, 'dim': 69, 'ws': 5, 'epoch': 100, 'minCount': 1, 'minCountLabel': 0, 'minn': 0, 'maxn': 0, 'neg': 5, 'wordNgrams': 2, 'loss': <loss_name.ova: 4>, 'bucket': 1762785, 'thread': 127, 'lrUpdateRate': 100, 't': 0.0001, 'label': '__label__', 'verbose': 2, 'pretrainedVectors': ''}\n",
      "precision: 0.5517, recall: 0.1852, f1: 0.2773, auc_score: 0.5923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'precision': 0.55175,\n",
       " 'recall': 0.18518207752978688,\n",
       " 'f1': 0.27729614273149894,\n",
       " 'auc_score': 0.5923386515733815}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fasttext autotune\n",
    "\n",
    "model = fasttext.train_supervised(\n",
    "    train_file,\n",
    "    loss=\"ova\",  # multi-label\n",
    "    autotuneValidationFile=valid_file,\n",
    "    autotuneDuration=300,  # 600,\n",
    "    autotuneMetric=\"f1\",\n",
    "    autotunePredictions=avg_num_of_labels_per_sample_valid,\n",
    ")\n",
    "\n",
    "print(model.__dict__)\n",
    "\n",
    "# rerun on validation\n",
    "predict_evaluate(model, valid_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c635c8-c5bd-4b5a-97e8-efc0f8db357f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16a4dcb-a68e-43ea-a564-d029a2dc3596",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa6e4f95-5207-43b9-8909-f6f77508c903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.583018</td>\n",
       "      <td>0.180903</td>\n",
       "      <td>0.276127</td>\n",
       "      <td>0.590233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.599039</td>\n",
       "      <td>0.177882</td>\n",
       "      <td>0.274309</td>\n",
       "      <td>0.588740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.610981</td>\n",
       "      <td>0.175533</td>\n",
       "      <td>0.272715</td>\n",
       "      <td>0.587577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.620066</td>\n",
       "      <td>0.172680</td>\n",
       "      <td>0.270132</td>\n",
       "      <td>0.586160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.629286</td>\n",
       "      <td>0.170918</td>\n",
       "      <td>0.268822</td>\n",
       "      <td>0.585288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold  precision    recall        f1  auc_score\n",
       "0       0.01   0.583018  0.180903  0.276127   0.590233\n",
       "1       0.02   0.599039  0.177882  0.274309   0.588740\n",
       "2       0.03   0.610981  0.175533  0.272715   0.587577\n",
       "3       0.04   0.620066  0.172680  0.270132   0.586160\n",
       "4       0.05   0.629286  0.170918  0.268822   0.585288"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grid search binarization threshold on validation set\n",
    "\n",
    "perf_by_thr = []\n",
    "for thr in np.arange(0.01, 1, 0.01):\n",
    "    r = predict_evaluate(model, valid_file, threshold=thr, verbose=False)\n",
    "    perf_by_thr.append({\"threshold\": thr, **r})\n",
    "\n",
    "df_perf_by_thr = pd.DataFrame(perf_by_thr)\n",
    "# sort by f1\n",
    "df_perf_by_thr = df_perf_by_thr.sort_values(\"f1\", ascending=False)\n",
    "df_perf_by_thr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c78505c2-8745-420c-992e-b9f12d643d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best threshold: 0.01\n",
      "perf on tmp_data/synthetic_v1/test_synthetic.txt --> precision: 0.8066, recall: 0.2555, f1: 0.3881, auc_score: 0.6276\n",
      "perf on tmp_data/synthetic_v1/test_synthetic_head.txt --> precision: 0.8147, recall: 0.2615, f1: 0.3959, auc_score: 0.6297\n",
      "perf on tmp_data/synthetic_v1/test_synthetic_medium.txt --> precision: 0.4542, recall: 0.1429, f1: 0.2174, auc_score: 0.5709\n",
      "perf on tmp_data/synthetic_v1/test_synthetic_tail.txt --> precision: 0.2192, recall: 0.0615, f1: 0.0960, auc_score: 0.5302\n"
     ]
    }
   ],
   "source": [
    "best_thr = df_perf_by_thr.iloc[0][\"threshold\"]\n",
    "print(f\"best threshold: {best_thr}\")\n",
    "\n",
    "# print(\"perf on test set --> \", end=\"\")\n",
    "# predict_evaluate(model, test_file, threshold=best_thr)\n",
    "\n",
    "for test_file in test_files:\n",
    "    print(f\"perf on {test_file} --> \", end=\"\")\n",
    "    predict_evaluate(model, test_file, threshold=best_thr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafd5ee8-3e05-4b96-82a9-d3d5750c426c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa99f022-2aeb-440c-be3f-e13b605c723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search k (top-k) on validation set\n",
    "\n",
    "perf_by_k = []\n",
    "for k in range(1, 11):\n",
    "    r = predict_evaluate(model, valid_file, k=k, verbose=False)\n",
    "    perf_by_k.append({\"k\": k, **r})\n",
    "\n",
    "df_perf_by_k = pd.DataFrame(perf_by_k)\n",
    "# sort by f1\n",
    "df_perf_by_k = df_perf_by_k.sort_values(\"f1\", ascending=False)\n",
    "df_perf_by_k.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5cc7ac-856b-468a-865a-47366e32882e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k = int(df_perf_by_k.iloc[0][\"k\"])\n",
    "print(f\"best k: {best_k}\")\n",
    "\n",
    "print(\"perf on test set --> \", end=\"\")\n",
    "predict_evaluate(model, test_file, k=best_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27c153a-65a8-4383-869e-07906e13b1b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c6871a-d58c-422f-9eef-4e4dc022b615",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df1e2e2-54fe-4425-9f55-86ab47853b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(input_file):\n",
    "    with open(input_file, \"r\") as f:\n",
    "        return [line.strip() for line in f]\n",
    "\n",
    "\n",
    "def append_file(file_a, file_b, n=None):\n",
    "    with open(file_a, \"a\") as fo, open(file_b, \"r\") as fi:\n",
    "        for i, line in enumerate(fi):\n",
    "            if n is not None and i >= n:\n",
    "                break\n",
    "            fo.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a962dbb4-08c1-4e96-9f45-0ae0dc778675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search ratios of original/synthetic data\n",
    "\n",
    "perf_by_ratio = []\n",
    "\n",
    "num_train = len(read_file(train_file))\n",
    "num_train_synth = len(read_file(train_synth_file))\n",
    "\n",
    "multipliers = [0, 0.5] + list(range(1, math.ceil(num_train_synth / num_train) + 1))\n",
    "# multipliers = [0, 0.5]\n",
    "for multiplier in multipliers:\n",
    "    print(\"\\n\\n\" + f\"Multiplier: {multiplier}\")\n",
    "    print(\"=\" * 50 + \"\\n\\n\")\n",
    "\n",
    "    n = min(num_train_synth, int(multiplier * num_train))\n",
    "\n",
    "    # copy train file\n",
    "    os.makedirs(os.path.dirname(tmp_train_file), exist_ok=True)\n",
    "    shutil.copy2(train_file, tmp_train_file)\n",
    "    # append some synthetic train data to train\n",
    "    append_file(tmp_train_file, train_synth_file, n)\n",
    "\n",
    "    model = fasttext.train_supervised(\n",
    "        tmp_train_file,\n",
    "        autotuneValidationFile=valid_file,\n",
    "        autotuneDuration=60,  # 300, 600\n",
    "        autotuneMetric=\"f1\",\n",
    "    )\n",
    "\n",
    "    r = predict_evaluate(model, valid_file)\n",
    "    perf_by_ratio.append({\"multiplier\": multiplier, **r, \"params\": model.__dict__})\n",
    "\n",
    "df_perf_by_ratio = pd.DataFrame(perf_by_ratio)\n",
    "df_perf_by_ratio = df_perf_by_ratio.sort_values(\"f1\", ascending=False)\n",
    "df_perf_by_ratio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245701c8-ae22-48f9-b81f-25f241c9bba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166b695e-d799-446d-99c9-d76c710835d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.dirname(tmp_train_file), exist_ok=True)\n",
    "shutil.copy2(train_file, tmp_train_file)\n",
    "# append some synthetic train data to train\n",
    "append_file(tmp_train_file, train_synth_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d0dfd0-692e-40fa-9939-8fe0f4f1c6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised(\n",
    "    tmp_train_file,\n",
    "    autotuneValidationFile=valid_file,\n",
    "    autotuneDuration=600,  # 300, 600\n",
    "    autotuneMetric=\"f1\",\n",
    ")\n",
    "\n",
    "r = predict_evaluate(model, valid_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9b076d-ebf5-48db-9c09-7c12177ead47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6367225-8aaf-4607-a872-2181b35879b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b750b51c-9d08-4fb1-a2e3-e5b0bb6edcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search\n",
    "\n",
    "param_grid = {\n",
    "    \"lr\": [0.1, 0.05, 0.01],\n",
    "    \"epoch\": [5, 10, 20],\n",
    "    \"wordNgrams\": [1, 2, 3],\n",
    "    \"dim\": [100, 200, 300],\n",
    "    \"minCount\": [1, 5, 10],\n",
    "}\n",
    "\n",
    "\n",
    "def grid_search(train_file, test_file, param_grid):\n",
    "    best_f1 = 0\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "\n",
    "    param_combinations = list(itertools.product(*param_grid.values()))\n",
    "    total_combinations = len(param_combinations)\n",
    "\n",
    "    for i, combination in enumerate(param_combinations, 1):\n",
    "        params = dict(zip(param_grid.keys(), combination))\n",
    "        print(f\"Evaluating combination {i}/{total_combinations}: {params}\")\n",
    "\n",
    "        model, metrics = train_predict_evaluate(train_file, test_file, params)\n",
    "\n",
    "        # print(f\"Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}\")\n",
    "\n",
    "        if metrics[\"f1\"] > best_f1:\n",
    "            best_f1 = metrics[\"f1\"]\n",
    "            best_params = params\n",
    "            best_model = model\n",
    "\n",
    "    return best_model, best_params, best_f1\n",
    "\n",
    "\n",
    "best_model, best_params, best_f1 = grid_search(train_file, valid_file, param_grid)\n",
    "\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best F1 score: {best_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eddccb5-0e3d-4bd4-9d4a-9e0a8121b73d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f70e7b0b-b172-4382-8e95-dbfbc7790e46",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e50bb4d-4a5a-419e-a633-d1c430640bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_path = \"/home/bhuang/icd_10/outputs/fasttext/synthetic/model_synthetic.bin\"\n",
    "\n",
    "os.makedirs(os.path.dirname(saved_model_path), exist_ok=True)\n",
    "model.save_model(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aded565-f282-4f62-bd97-4a5b59b1ae3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af319e02-5041-4b8b-aff5-f3af0c6f7d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload\n",
    "model_path = saved_model_path\n",
    "\n",
    "model = fasttext.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d78d55-30b6-4e53-a22e-8f8eafeec2d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8056e95-2fd7-4480-8596-30a64a4ff905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__P55', '__label__Z31', '__label__F41'),\n",
       " array([0.64423513, 0.60019839, 0.56986266]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"### Discharge Summary\n",
    "\n",
    "**Patient: [Nom du patient]**\n",
    "**Date de naissance: [Date de naissance]**\n",
    "**Numéro de dossier: [Numéro de dossier]**\n",
    "**Date d'admission: [Date d'admission]**\n",
    "**Date de sortie: [Date de sortie]**\n",
    "\n",
    "**Raison de l'admission:**\n",
    "Le patient a été admis pour une évaluation et une prise en charge de symptômes récurrents d'infections respiratoires et cutanées. Le patient présente une histoire médicale complexe marquée par une susceptibilité accrue aux infections, suggérant une possible déficience immunitaire.\n",
    "\n",
    "**Historique médical:**\n",
    "Le patient a une longue histoire d'infections récurrentes, y compris des pneumonies et des infections cutanées. Les antécédents familiaux révèlent des cas similaires, ce qui renforce l'hypothèse d'une déficience immunitaire héréditaire.\n",
    "\n",
    "**Évaluation clinique:**\n",
    "Lors de l'admission, le patient présentait des symptômes de pneumonie, y compris une toux productive, une fièvre élevée et des douleurs thoraciques. L'examen physique a révélé des râles crépitants bilatéraux. Une éruption cutanée était également présente sur les bras et le dos, suggérant une infection bactérienne.\n",
    "\n",
    "**Résultats des examens:**\n",
    "Les analyses de laboratoire ont montré une diminution des taux d'immunoglobulines, en particulier les IgG, IgA et IgM. Les tests de fonction immunitaire ont également révélé une réponse anormale aux vaccins, indiquant une déficience dans la production d'anticorps.\n",
    "\n",
    "**Traitement et gestion:**\n",
    "Le patient a été traité avec des antibiotiques à large spectre pour les infections respiratoires et cutanées. Des immunoglobulines intraveineuses (IVIG) ont été initiées pour compenser la déficience en anticorps. Une consultation en immunologie a été demandée pour une évaluation plus approfondie et un plan de gestion à long terme.\n",
    "\n",
    "**Recommandations à la sortie:**\n",
    "Le patient doit continuer les traitements par IVIG selon le calendrier prescrit. Un suivi régulier avec un immunologue est nécessaire pour surveiller les taux d'immunoglobulines et ajuster le traitement si nécessaire. Le patient et sa famille ont été informés de l'importance de la vaccination et des mesures d'hygiène pour prévenir les infections.\n",
    "\n",
    "**Plan de suivi:**\n",
    "Un rendez-vous de suivi est prévu dans deux semaines avec le médecin traitant et l'immunologue. Des analyses de laboratoire seront répétées pour évaluer l'efficacité du traitement et ajuster les doses de IVIG si nécessaire.\n",
    "\n",
    "**Signature du médecin:**\n",
    "[Nom du médecin]\n",
    "[Titre du médecin]\n",
    "[Date]\"\"\"\n",
    "\n",
    "text = re.sub(\"\\n\", \"\", text)\n",
    "model.predict(text, k=3) #, threshold=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01df00e2-dd31-4fb8-ab5e-7d6bc7e0394e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocd-10",
   "language": "python",
   "name": "ocd-10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
